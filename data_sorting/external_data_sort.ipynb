{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External sort algorithm on large data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, constants and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebook_mode: int = int(\n",
    "    input(\n",
    "        \"\"\"\n",
    "    Select notebook mode: \n",
    "    1. Google Colab  2. Local\n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if notebook_mode == 1:\n",
    "    # Run on Colab.\n",
    "    INPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/data/\"\n",
    "    SCRIPT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/training_testing/data_labelling/\"\n",
    "    OUTPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/output/\"\n",
    "    os.system(command=\"cp {}custom_model.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}inference.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}utils.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}operation.py .\".format(SCRIPT_PATH))\n",
    "elif notebook_mode == 2:\n",
    "    INPUT_PATH: str = \"../../../../data/\"\n",
    "    SCRIPT_PATH: str = \"./\"\n",
    "    OUTPUT_PATH: str = \"./out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(command=\"rm -rf {}\".format(OUTPUT_PATH))\n",
    "try:\n",
    "    os.mkdir(path=OUTPUT_PATH)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOS2E03230475']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "files: list[str] = os.listdir(path=INPUT_PATH)\n",
    "files = [f for f in files if f.endswith(\".zip\")]\n",
    "\n",
    "sensor_names: list[str] = [name.split(\"_\")[0] for name in files]\n",
    "print(sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "window_size: int = 600  # 300: 10 seconds\n",
    "window_per_epoch: int = 200\n",
    "epoch: int = 1\n",
    "batch_size: int = 64\n",
    "# random.seed(715) # 715 looks good.\n",
    "random.seed(785)  # 785 makes \"other\" looks bad, otherwise is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the large data file and sort these partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas.io.parsers.readers\n",
    "\n",
    "for f in files:\n",
    "    os.system(\"rm -rf {}{}_*.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]))\n",
    "    # Path(\"{}{}.txt\".format(OUTPUT_PATH, f.split(\"_\")[0])).touch()\n",
    "    data_chunks: pandas.io.parsers.readers.TextFileReader = pd.read_csv(\n",
    "        filepath_or_buffer=\"{}/{}\".format(INPUT_PATH, f),\n",
    "        # nrows=14000,\n",
    "        chunksize=window_size * 100,\n",
    "    )\n",
    "    df_count: int = 1\n",
    "    raw_data: pd.DataFrame\n",
    "    for raw_data in data_chunks:\n",
    "        # Sort values based on timestamps.\n",
    "        raw_data.sort_values(\n",
    "            by=[\"timestamps\"],\n",
    "            ascending=True,\n",
    "            inplace=True,\n",
    "        )\n",
    "        raw_data = raw_data.reset_index(drop=True)\n",
    "        raw_data.to_csv(\n",
    "            path_or_buf=\"{}{}_{}.txt\".format(\n",
    "                OUTPUT_PATH,\n",
    "                f.split(\"_\")[0],\n",
    "                df_count,\n",
    "            ),\n",
    "            header=True,\n",
    "            index=False,\n",
    "        )\n",
    "        df_count += 1\n",
    "\n",
    "        # if df_count == 6:\n",
    "        #     break\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def merge_external_files(\n",
    "    f1: str,\n",
    "    f2: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Read and merge-sort two text file and output the merged file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        f1: str\n",
    "            Path to the first data file.\n",
    "\n",
    "        f2: str\n",
    "            Path to the second data file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Need a header row to keep the format correct.\n",
    "    header_row: str = ...\n",
    "    # Read the first file.\n",
    "    with open(f1) as file:\n",
    "        rows: list[str] = file.readlines()\n",
    "        header_row = rows[0]\n",
    "        rows = rows[1:]\n",
    "        file1: np.ndarray = np.array([r.rstrip(\"\\n\") for r in rows])\n",
    "\n",
    "    # Read the second file.\n",
    "    with open(f2) as file:\n",
    "        rows: list[str] = file.readlines()\n",
    "        rows = rows[1:]\n",
    "        file2: np.ndarray = np.array([r.rstrip(\"\\n\") for r in rows])\n",
    "\n",
    "    len_1: int = file1.size\n",
    "    len_2: int = file2.size\n",
    "    i1: int = 0\n",
    "    i2: int = 0\n",
    "\n",
    "    file_uid: int = random.randint(0, 9999999)\n",
    "    os.system(\n",
    "        \"rm -rf {}merged_{}.txt\".format(\n",
    "            OUTPUT_PATH,\n",
    "            file_uid,\n",
    "        )\n",
    "    )\n",
    "    Path(\n",
    "        \"{}merged_{}.txt\".format(\n",
    "            OUTPUT_PATH,\n",
    "            file_uid,\n",
    "        )\n",
    "    ).touch()\n",
    "    with open(\n",
    "        file=\"{}merged_{}.txt\".format(\n",
    "            OUTPUT_PATH,\n",
    "            file_uid,\n",
    "        ),\n",
    "        mode=\"a\",\n",
    "    ) as output_file:\n",
    "        # Write the head row first.\n",
    "        output_file.write(header_row)\n",
    "        # Implementing the \"merge\" part of the merge sort algorithm externally.\n",
    "        while i1 < len_1 and i2 < len_2:\n",
    "            # if np.datetime64(file1[i1][4]) <= np.datetime64(file2[i2][4]):\n",
    "            time1: np.datetime64 = np.datetime64(file1[i1].split(sep=\",\")[4])\n",
    "            time2: np.datetime64 = np.datetime64(file2[i2].split(sep=\",\")[4])\n",
    "            if time1 <= time2:\n",
    "                # output_string: str = \",\".join(file1[i1])\\\n",
    "                output_string: str = file1[i1] + \"\\n\"\n",
    "                output_file.write(output_string)\n",
    "                i1 += 1\n",
    "            else:\n",
    "                # output_string: str = \",\".join(file2[i2])\n",
    "                output_string: str = file2[i2] + \"\\n\"\n",
    "                output_file.write(output_string)\n",
    "                i2 += 1\n",
    "\n",
    "        while i1 < len_1:\n",
    "            output_string: str = file1[i1] + \"\\n\"\n",
    "            output_file.write(output_string)\n",
    "            i1 += 1\n",
    "        while i2 < len_2:\n",
    "            output_string: str = file2[i2] + \"\\n\"\n",
    "            output_file.write(output_string)\n",
    "            i2 += 1\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # Remove the two files after merged.\n",
    "    os.system(command=\"rm -rf {} {}\".format(f1, f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    split_files: list[str] = os.listdir(path=OUTPUT_PATH)\n",
    "    no_of_files: int = len(split_files)\n",
    "\n",
    "    if no_of_files == 1:\n",
    "        break\n",
    "\n",
    "    if no_of_files % 2 == 0:\n",
    "        for file_index in range(0, no_of_files, 2):\n",
    "            merge_external_files(\n",
    "                f1=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index],\n",
    "                ),\n",
    "                f2=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index + 1],\n",
    "                ),\n",
    "            )\n",
    "            gc.collect()\n",
    "    else:\n",
    "        for file_index in range(0, no_of_files - 1, 2):\n",
    "            merge_external_files(\n",
    "                f1=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index],\n",
    "                ),\n",
    "                f2=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index + 1],\n",
    "                ),\n",
    "            )\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>nickname</th>\n",
       "      <th>animalID</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>timestamps</th>\n",
       "      <th>acc_axis1</th>\n",
       "      <th>acc_axis2</th>\n",
       "      <th>acc_axis3</th>\n",
       "      <th>acc_mag</th>\n",
       "      <th>lpf_axis1</th>\n",
       "      <th>...</th>\n",
       "      <th>dis_axis1_denoised</th>\n",
       "      <th>dis_axis2_denoised</th>\n",
       "      <th>dis_axis3_denoised</th>\n",
       "      <th>dis_mag_denoised</th>\n",
       "      <th>tilt_axis1</th>\n",
       "      <th>tilt_axis2</th>\n",
       "      <th>tilt_axis3</th>\n",
       "      <th>tilt_axis1_denoised</th>\n",
       "      <th>tilt_axis2_denoised</th>\n",
       "      <th>tilt_axis3_denoised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOS2E03230475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-04-14 18:01:01.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1.011302</td>\n",
       "      <td>0.636648</td>\n",
       "      <td>...</td>\n",
       "      <td>1874.156185</td>\n",
       "      <td>1694.906462</td>\n",
       "      <td>192.005856</td>\n",
       "      <td>2534.173547</td>\n",
       "      <td>39.120814</td>\n",
       "      <td>18.021817</td>\n",
       "      <td>44.646077</td>\n",
       "      <td>39.105397</td>\n",
       "      <td>18.027755</td>\n",
       "      <td>44.634478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOS2E03230475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-04-14 18:01:01.034</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.006544</td>\n",
       "      <td>0.636649</td>\n",
       "      <td>...</td>\n",
       "      <td>1875.197894</td>\n",
       "      <td>1695.848197</td>\n",
       "      <td>192.113417</td>\n",
       "      <td>2535.581948</td>\n",
       "      <td>39.120815</td>\n",
       "      <td>18.021889</td>\n",
       "      <td>44.646120</td>\n",
       "      <td>39.105401</td>\n",
       "      <td>18.027766</td>\n",
       "      <td>44.634488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOS2E03230475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-04-14 18:01:01.067</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1.002415</td>\n",
       "      <td>0.636650</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.239602</td>\n",
       "      <td>1696.789933</td>\n",
       "      <td>192.220978</td>\n",
       "      <td>2536.990348</td>\n",
       "      <td>39.120819</td>\n",
       "      <td>18.021961</td>\n",
       "      <td>44.646166</td>\n",
       "      <td>39.105405</td>\n",
       "      <td>18.027776</td>\n",
       "      <td>44.634498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOS2E03230475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-04-14 18:01:01.100</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1.003691</td>\n",
       "      <td>0.636651</td>\n",
       "      <td>...</td>\n",
       "      <td>1877.281309</td>\n",
       "      <td>1697.731668</td>\n",
       "      <td>192.328538</td>\n",
       "      <td>2538.398747</td>\n",
       "      <td>39.120820</td>\n",
       "      <td>18.022032</td>\n",
       "      <td>44.646210</td>\n",
       "      <td>39.105409</td>\n",
       "      <td>18.027787</td>\n",
       "      <td>44.634509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOS2E03230475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2023-04-14 18:01:01.134</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.006544</td>\n",
       "      <td>0.636651</td>\n",
       "      <td>...</td>\n",
       "      <td>1878.323016</td>\n",
       "      <td>1698.673403</td>\n",
       "      <td>192.436099</td>\n",
       "      <td>2539.807146</td>\n",
       "      <td>39.120823</td>\n",
       "      <td>18.022104</td>\n",
       "      <td>44.646254</td>\n",
       "      <td>39.105413</td>\n",
       "      <td>18.027798</td>\n",
       "      <td>44.634519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_number  nickname  animalID  sample_rate               timestamps  \\\n",
       "0  MOS2E03230475       NaN       NaN           30  2023-04-14 18:01:01.000   \n",
       "1  MOS2E03230475       NaN       NaN           30  2023-04-14 18:01:01.034   \n",
       "2  MOS2E03230475       NaN       NaN           30  2023-04-14 18:01:01.067   \n",
       "3  MOS2E03230475       NaN       NaN           30  2023-04-14 18:01:01.100   \n",
       "4  MOS2E03230475       NaN       NaN           30  2023-04-14 18:01:01.134   \n",
       "\n",
       "   acc_axis1  acc_axis2  acc_axis3   acc_mag  lpf_axis1  ...  \\\n",
       "0      0.645      0.309      0.715  1.011302   0.636648  ...   \n",
       "1      0.633      0.309      0.719  1.006544   0.636649  ...   \n",
       "2      0.629      0.313      0.715  1.002415   0.636650  ...   \n",
       "3      0.633      0.309      0.715  1.003691   0.636651  ...   \n",
       "4      0.633      0.309      0.719  1.006544   0.636651  ...   \n",
       "\n",
       "   dis_axis1_denoised  dis_axis2_denoised  dis_axis3_denoised  \\\n",
       "0         1874.156185         1694.906462          192.005856   \n",
       "1         1875.197894         1695.848197          192.113417   \n",
       "2         1876.239602         1696.789933          192.220978   \n",
       "3         1877.281309         1697.731668          192.328538   \n",
       "4         1878.323016         1698.673403          192.436099   \n",
       "\n",
       "   dis_mag_denoised  tilt_axis1  tilt_axis2  tilt_axis3  tilt_axis1_denoised  \\\n",
       "0       2534.173547   39.120814   18.021817   44.646077            39.105397   \n",
       "1       2535.581948   39.120815   18.021889   44.646120            39.105401   \n",
       "2       2536.990348   39.120819   18.021961   44.646166            39.105405   \n",
       "3       2538.398747   39.120820   18.022032   44.646210            39.105409   \n",
       "4       2539.807146   39.120823   18.022104   44.646254            39.105413   \n",
       "\n",
       "   tilt_axis2_denoised  tilt_axis3_denoised  \n",
       "0            18.027755            44.634478  \n",
       "1            18.027766            44.634488  \n",
       "2            18.027776            44.634498  \n",
       "3            18.027787            44.634509  \n",
       "4            18.027798            44.634519  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunked_df: pandas.io.parsers.readers.TextFileReader = pd.read_csv(\n",
    "    filepath_or_buffer=\"./out/merged_2785301.txt\",\n",
    "    chunksize=600,\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "df: pd.DataFrame\n",
    "for df in chunked_df:\n",
    "    ts: np.ndarray = df[\"timestamps\"].to_numpy()\n",
    "    is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "    is_sorted(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts: np.ndarray = test_df[\"timestamps\"].to_numpy()\n",
    "\n",
    "is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "is_sorted(ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
