{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External sort algorithm on large data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, constants and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebook_mode: int = int(\n",
    "    input(\n",
    "        \"\"\"\n",
    "    Select notebook mode:\n",
    "    1. Google Colab  2. Local\n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if notebook_mode == 1:\n",
    "    # Run on Colab.\n",
    "    INPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/data/\"\n",
    "    SCRIPT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/training_testing/data_labelling/\"\n",
    "    # OUTPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/output/\"\n",
    "    OUTPUT_PATH: str = \"./out/\"\n",
    "    os.system(command=\"cp {}custom_model.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}inference.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}utils.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}operation.py .\".format(SCRIPT_PATH))\n",
    "elif notebook_mode == 2:\n",
    "    INPUT_PATH: str = \"../../../../data/\"\n",
    "    SCRIPT_PATH: str = \"./\"\n",
    "    OUTPUT_PATH: str = \"./out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(command=\"rm -rf {}\".format(OUTPUT_PATH))\n",
    "try:\n",
    "    os.mkdir(path=OUTPUT_PATH)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOS2E03230475']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "files: list[str] = os.listdir(path=INPUT_PATH)\n",
    "files = [f for f in files if f.endswith(\".zip\")]\n",
    "\n",
    "sensor_names: list[str] = [name.split(\"_\")[0] for name in files]\n",
    "print(sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "window_size: int = 600  # 300: 10 seconds\n",
    "window_per_epoch: int = 200\n",
    "epoch: int = 1\n",
    "batch_size: int = 64\n",
    "chunk_size: int = 300\n",
    "# random.seed(715) # 715 looks good.\n",
    "random.seed(785)  # 785 makes \"other\" looks bad, otherwise is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the large data file and sort these partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas.io.parsers.readers\n",
    "\n",
    "for f in files:\n",
    "    os.system(\"rm -rf {}{}_*.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]))\n",
    "    # Path(\"{}{}.txt\".format(OUTPUT_PATH, f.split(\"_\")[0])).touch()\n",
    "    data_chunks: pandas.io.parsers.readers.TextFileReader = pd.read_csv(\n",
    "        filepath_or_buffer=\"{}/{}\".format(INPUT_PATH, f),\n",
    "        # nrows=14000,\n",
    "        chunksize=window_size * 1,\n",
    "        # chunksize=1,\n",
    "    )\n",
    "    df_count: int = 0\n",
    "    raw_data: pd.DataFrame\n",
    "    for raw_data in data_chunks:\n",
    "        # Sort values based on timestamps.\n",
    "        raw_data.sort_values(\n",
    "            by=[\"timestamps\"],\n",
    "            ascending=True,\n",
    "            inplace=True,\n",
    "        )\n",
    "        raw_data = raw_data.reset_index(drop=True)\n",
    "        raw_data.to_csv(\n",
    "            path_or_buf=\"{}{}_{}.txt\".format(\n",
    "                OUTPUT_PATH,\n",
    "                f.split(\"_\")[0],\n",
    "                df_count,\n",
    "            ),\n",
    "            header=True,\n",
    "            index=False,\n",
    "        )\n",
    "        df_count += 1\n",
    "\n",
    "        if df_count == 5:\n",
    "            break\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import merge_external_files, merge_external_files_chunks\n",
    "\n",
    "while True:\n",
    "    split_files: list[str] = os.listdir(path=OUTPUT_PATH)\n",
    "    no_of_files: int = len(split_files)\n",
    "\n",
    "    if no_of_files == 1:\n",
    "        break\n",
    "\n",
    "    if no_of_files % 2 == 0:\n",
    "        for file_index in range(0, no_of_files, 2):\n",
    "            merge_external_files_chunks(\n",
    "                f1=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index],\n",
    "                ),\n",
    "                f2=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index + 1],\n",
    "                ),\n",
    "                output_path=OUTPUT_PATH,\n",
    "                chunk_size=chunk_size,\n",
    "            )\n",
    "            gc.collect()\n",
    "    else:\n",
    "        for file_index in range(0, no_of_files - 1, 2):\n",
    "            merge_external_files_chunks(\n",
    "                f1=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index],\n",
    "                ),\n",
    "                f2=\"{}{}\".format(\n",
    "                    OUTPUT_PATH,\n",
    "                    split_files[file_index + 1],\n",
    "                ),\n",
    "                output_path=OUTPUT_PATH,\n",
    "                chunk_size=chunk_size,\n",
    "            )\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_6565788.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_files: list[str] = os.listdir(\"./out/\")\n",
    "print(output_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_6565788.txt\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "\n",
    "output_files: list[str] = os.listdir(\"./out/\")\n",
    "print(output_files[0])\n",
    "\n",
    "with open(\n",
    "    file=\"./out/{}\".format(output_files[0]),\n",
    "    mode=\"rb\",\n",
    ") as f_in, gzip.open(\n",
    "    filename=\"./out/{}_sorted.gz\".format(sensor_names[0]),\n",
    "    mode=\"wb\",\n",
    ") as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.parsers.readers\n",
    "\n",
    "chunked_df: pandas.io.parsers.readers.TextFileReader = pd.read_csv(\n",
    "    filepath_or_buffer=\"./out/{}\".format(output_files[0]),\n",
    "    chunksize=600,\n",
    "    sep=\",\",\n",
    ")\n",
    "\n",
    "df: pd.DataFrame\n",
    "last_row: np.datetime64 = np.datetime64(\"1970-01-01T00:00:00.000\")\n",
    "for df in chunked_df:\n",
    "    ts: np.ndarray = df[\"timestamps\"].to_numpy(dtype=np.datetime64)\n",
    "    if not last_row < ts[0]:\n",
    "        print(False)\n",
    "        break\n",
    "    last_row = ts[-1]\n",
    "    is_sorted = lambda a: np.all(a[:-1] <= a[1:])\n",
    "    if not is_sorted(ts):\n",
    "        print(False)\n",
    "        break\n",
    "    gc.collect()\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
