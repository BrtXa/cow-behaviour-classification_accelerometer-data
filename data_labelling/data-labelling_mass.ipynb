{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cow behaviour labelling\n",
    "Using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebook_mode: int = int(\n",
    "    input(\n",
    "        \"\"\"\n",
    "    Select notebook mode: \n",
    "    1. Google Colab  2. Local\n",
    "    \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if notebook_mode == 1:\n",
    "    # Run on Colab.\n",
    "    INPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/data/\"\n",
    "    SCRIPT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/training_testing/data_labelling/\"\n",
    "    OUTPUT_PATH: str = \"/content/drive/MyDrive/Ellinbank/video_observation/output/\"\n",
    "    os.system(command=\"cp {}custom_model.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}inference.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}utils.py .\".format(SCRIPT_PATH))\n",
    "    os.system(command=\"cp {}operation.py .\".format(SCRIPT_PATH))\n",
    "elif notebook_mode == 2:\n",
    "    INPUT_PATH: str = \"../../../../data/\"\n",
    "    SCRIPT_PATH: str = \"./\"\n",
    "    OUTPUT_PATH: str = \"./out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOS2E03230475']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "files: list[str] = os.listdir(path=INPUT_PATH)\n",
    "files = [f for f in files if f.endswith(\".zip\")]\n",
    "\n",
    "sensor_names: list[str] = [name.split(\"_\")[0] for name in files]\n",
    "print(sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 13:42:36.944294: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-19 13:42:36.969587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-19 13:42:36.969634: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-19 13:42:36.969668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-19 13:42:36.975390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-19 13:42:36.975877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 13:42:37.919837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "training_device: str = \"cpu\"\n",
    "\n",
    "if str.lower(training_device) == \"cpu\":\n",
    "    tf.config.set_visible_devices(\n",
    "        devices=[],\n",
    "        device_type=\"GPU\",\n",
    "    )\n",
    "else:\n",
    "    physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "    config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "window_size: int = 600  # 300: 10 seconds\n",
    "window_per_epoch: int = 200\n",
    "epoch: int = 1\n",
    "batch_size: int = 64\n",
    "# random.seed(715) # 715 looks good.\n",
    "random.seed(785)  # 785 makes \"other\" looks bad, otherwise is good.\n",
    "\n",
    "\n",
    "model: tf.keras.Model = tf.keras.models.load_model(\n",
    "    filepath=\"{}cow_model.keras\".format(SCRIPT_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in files:\n",
    "#     data_chunks: pd.DataFrame = pd.read_csv(\n",
    "#         filepath_or_buffer=\"{}/{}\".format(INPUT_PATH, f),\n",
    "#     )\n",
    "\n",
    "# data_chunks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas.io.parsers.readers\n",
    "from operation import clean_data, label_data\n",
    "\n",
    "saved_df: pd.DataFrame = ...\n",
    "saved_labels: np.ndarray = ...\n",
    "\n",
    "for f in files:\n",
    "    os.system(\"rm -rf {}{}.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]))\n",
    "    os.system(\"rm -rf {}{}_timestamps.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]))\n",
    "    Path(\"{}{}.txt\".format(OUTPUT_PATH, f.split(\"_\")[0])).touch()\n",
    "    data_chunks: pandas.io.parsers.readers.TextFileReader = pd.read_csv(\n",
    "        filepath_or_buffer=\"{}/{}\".format(INPUT_PATH, f),\n",
    "        # nrows=14000,\n",
    "        chunksize=window_size * 10,\n",
    "    )\n",
    "\n",
    "    for raw_data in data_chunks:\n",
    "        full_data: pd.DataFrame = clean_data(full_data=raw_data)\n",
    "        labels: np.ndarray = label_data(\n",
    "            raw_data=full_data,\n",
    "            model=model,\n",
    "            window_size=window_size,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        saved_df = full_data\n",
    "        saved_labels = labels\n",
    "\n",
    "        with open(\n",
    "            file=\"{}{}.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]),\n",
    "            mode=\"ab\",\n",
    "        ) as file:\n",
    "            np.savetxt(\n",
    "                fname=file,\n",
    "                X=labels,\n",
    "                fmt=\"%s\",\n",
    "            )\n",
    "\n",
    "        time_stamps: np.ndarray = full_data[\"timestamps\"].to_numpy()\n",
    "        with open(\n",
    "            file=\"{}{}_timestamps.txt\".format(OUTPUT_PATH, f.split(\"_\")[0]),\n",
    "            mode=\"ab\",\n",
    "        ) as file:\n",
    "            np.savetxt(\n",
    "                fname=file,\n",
    "                X=time_stamps,\n",
    "                fmt=\"%s\",\n",
    "            )\n",
    "\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_size: int = window_size - (len(saved_df) - saved_labels.size)\n",
    "overlapping_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_window: pd.DataFrame = saved_df[-600:]\n",
    "overlapping_labels: np.ndarray = label_data(\n",
    "    raw_data=last_window,\n",
    "    model=model,\n",
    "    window_size=window_size,\n",
    "    batch_size=batch_size,\n",
    ")[:overlapping_size]\n",
    "\n",
    "overlapping_labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_labels_overlap: np.ndarray = saved_labels[-overlapping_size:]\n",
    "saved_labels_overlap.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(overlapping_labels == saved_labels_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
